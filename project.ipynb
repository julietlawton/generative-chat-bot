{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chardet\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from evaluate import load\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILENAME = \"movie_conversations.pkl\"\n",
    "MAX_TOKEN_LENGTH = 1024\n",
    "dataset_generated = False\n",
    "\n",
    "if os.path.exists(DATASET_FILENAME):\n",
    "    dataset_generated = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Detect encoding of the movie lines file\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # with open(cwd + \"/movie_lines/movie_lines.txt\", \"rb\") as f:\n",
    "    #     result = chardet.detect(f.read())\n",
    "    #     movie_lines_encoding = result[\"encoding\"]\n",
    "\n",
    "    # with open(cwd + \"/movie_lines/movie_conversations.txt\", \"rb\") as f:\n",
    "    #     result = chardet.detect(f.read())\n",
    "    #     movie_conversations_encoding = result[\"encoding\"]\n",
    "\n",
    "    # print(movie_lines_encoding)\n",
    "    # print(movie_conversations_encoding)\n",
    "    movie_lines_encoding = \"Windows-1252\"\n",
    "    movie_conversations_encoding = \"ascii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Collect individual movie lines\n",
    "    with open(cwd + \"/movie_lines/movie_lines.txt\", \"r\", encoding=movie_lines_encoding) as f:\n",
    "        content = f.read()\n",
    "\n",
    "    lines = content.split(\"\\n\")\n",
    "\n",
    "    # Print first 5 lines and verify length is correct\n",
    "    print(lines[:5])\n",
    "\n",
    "    # Remove last element of lines because its an empty string\n",
    "    lines = lines[:-1]\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Initialize containers for values to put in dataframe\n",
    "    line_numbers_dict = {}\n",
    "\n",
    "    for line in lines:\n",
    "        # Split on whitespace\n",
    "        split = line.split(\" \")\n",
    "        line_number = split[0]\n",
    "        character_id = split[2]\n",
    "\n",
    "        # Extract the text after the last \"+\" character\n",
    "        l = re.split(r'\\+\\s+(?=[^+]*$)', line)[-1]\n",
    "        line_numbers_dict[line_number] = (character_id, l)\n",
    "\n",
    "\n",
    "    # Create dataframe from extracted values\n",
    "    print(dict(itertools.islice(line_numbers_dict.items(), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Collect movie conversation lists\n",
    "    with open(cwd + \"/movie_lines/movie_conversations.txt\", \"r\", encoding=movie_conversations_encoding) as f:\n",
    "        content = f.read()\n",
    "\n",
    "    lines = content.split(\"\\n\")\n",
    "\n",
    "    # Print first 5 lines and verify length is correct\n",
    "    print(lines[:5])\n",
    "\n",
    "    # Remove last element of lines because its an empty string\n",
    "    lines = lines[:-1]\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Initialize containers for values to put in dataframe\n",
    "    speaker1_ids = []\n",
    "    speaker2_ids = []\n",
    "    conversation_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Split on whitespace\n",
    "        split = line.split(\" \")\n",
    "        speaker1_ids.append(split[0])\n",
    "        speaker2_ids.append(split[2])\n",
    "\n",
    "        # Extract the text after the last \"+\" character\n",
    "        l = re.split(r'\\+\\s+(?=[^+]*$)', line)[-1]\n",
    "        l = ast.literal_eval(l)\n",
    "        conversation_lines.append(l)\n",
    "\n",
    "\n",
    "    # Create dataframe from extracted values\n",
    "    movie_conversations = pd.DataFrame(list(zip(speaker1_ids, speaker2_ids, conversation_lines)), columns=[\"speaker1_id\", \"speaker2_id\", \"conversation_lines\"])\n",
    "    display(movie_conversations.head())\n",
    "    movie_conversations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for turning movie lines into multi-turn conversations for training\n",
    "def create_conversation_turns(row):\n",
    "    speaker1 = row[\"speaker1_id\"]\n",
    "    conversation_list = row[\"conversation_lines\"]\n",
    "    convo = \"\"\n",
    "    # For each line, add it to the conversation with a role label\n",
    "    for i, line_id in enumerate(conversation_list):\n",
    "        movie_line = line_numbers_dict[line_id]\n",
    "        text = movie_line[1]\n",
    "\n",
    "        # Ensure the conversations end with agent response\n",
    "        if i == len(conversation_list) - 1 and i % 2 == 0:\n",
    "            continue\n",
    "\n",
    "        if i%2 == 0:\n",
    "            convo += f\"<USER>: {text} \\n\"\n",
    "        else:\n",
    "            convo += f\"<AGENT>: {text} \\n\"\n",
    "\n",
    "        # if movie_line[0] == speaker1:\n",
    "        #     convo += f\"<USER>: {text} \\n\"\n",
    "        # else:\n",
    "        #     convo += f\"<AGENT>: {text} \\n\"\n",
    "        \n",
    "    return convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Try it on a sample for testing\n",
    "    sample = movie_conversations.copy().iloc[:2]\n",
    "    sample[\"conversation\"] = sample.apply(create_conversation_turns, axis=1)\n",
    "    display(sample)\n",
    "\n",
    "    # Call create_conversation_turns on every row of the dataframe\n",
    "    movie_conversations[\"conversation\"] = movie_conversations.apply(create_conversation_turns, axis=1)\n",
    "\n",
    "    # Drop speaker id columns because they aren't needed anymore\n",
    "    movie_conversations.drop(columns=[\"speaker1_id\", \"speaker2_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    display(movie_conversations.head())\n",
    "    print(movie_conversations[\"conversation\"].head(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Get the token count for each conversation so we can split the ones that are too long\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "    movie_conversations[\"token_count\"] = movie_conversations[\"conversation\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "    movie_conversations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:    \n",
    "    # Get the conversation entries that are over the token limit\n",
    "    over_token_limit = movie_conversations[movie_conversations[\"token_count\"] > MAX_TOKEN_LENGTH].index\n",
    "    print(over_token_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # NOTE: Be careful not to run this more than once without reseting the dataframe\n",
    "    new_entries = []\n",
    "\n",
    "    # For each conversation that is too long, split it in half\n",
    "    for idx in over_token_limit:\n",
    "        lines_to_split = movie_conversations.iloc[idx][\"conversation_lines\"]\n",
    "        split_idx = (len(lines_to_split)//2)\n",
    "        first_half = lines_to_split[:split_idx]\n",
    "        second_half = lines_to_split[split_idx:]\n",
    "\n",
    "        first_convo = \"\"\n",
    "        second_convo = \"\"\n",
    "        # For each line, add it to the conversation\n",
    "        for i, line_id in enumerate(first_half):\n",
    "            movie_line = line_numbers_dict[line_id]\n",
    "            text = movie_line[1]\n",
    "\n",
    "            # Ensure the conversations end with agent response\n",
    "            if i == len(first_half) - 1 and i % 2 == 0:\n",
    "                continue\n",
    "\n",
    "            if i%2 == 0:\n",
    "                first_convo += f\"<USER>: {text} \\n\"\n",
    "            else:\n",
    "                first_convo += f\"<AGENT>: {text} \\n\"\n",
    "\n",
    "        new_entries.append({\"conversation_lines\": first_half, \"conversation\": first_convo})\n",
    "\n",
    "        for i, line_id in enumerate(second_half):\n",
    "            movie_line = line_numbers_dict[line_id]\n",
    "            text = movie_line[1]\n",
    "\n",
    "            # Ensure the conversations end with agent response\n",
    "            if i == len(second_half) - 1 and i % 2 == 0:\n",
    "                continue\n",
    "\n",
    "            if i%2 == 0:\n",
    "                second_convo += f\"<USER>: {text} \\n\"\n",
    "            else:\n",
    "                second_convo += f\"<AGENT>: {text} \\n\"\n",
    "\n",
    "        new_entries.append({\"conversation_lines\": second_half, \"conversation\": second_convo})\n",
    "\n",
    "    # Add the new entries from splitting and drop the originals\n",
    "    movie_conversations = pd.concat([movie_conversations, pd.DataFrame(new_entries)], axis=0, ignore_index=True)\n",
    "    movie_conversations.drop(index=over_token_limit, inplace=True)\n",
    "\n",
    "    movie_conversations.reset_index(inplace=True, drop=True)\n",
    "    movie_conversations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Check that no conversations are over the token limit\n",
    "    display(movie_conversations[movie_conversations[\"token_count\"] > MAX_TOKEN_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop line numbers and token count because they aren't needed anymore\n",
    "if not dataset_generated:\n",
    "    movie_conversations.drop(columns=[\"conversation_lines\", \"token_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataframe from file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;USER&gt;: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n&lt;AGENT&gt;: Well, I thought we'd start with pronunciation, if that's okay with you. \\n&lt;USER&gt;: Not the hacking and gagging and spitting part.  Please. \\n&lt;AGENT&gt;: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;USER&gt;: You're asking me out.  That's so cute. What's your name again? \\n&lt;AGENT&gt;: Forget it. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;USER&gt;: No, no, it's my fault -- we didn't have a proper introduction --- \\n&lt;AGENT&gt;: Cameron. \\n&lt;USER&gt;: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \\n&lt;AGENT&gt;: Seems like she could get a date easy enough... \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;USER&gt;: Why? \\n&lt;AGENT&gt;: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;USER&gt;: Gosh, if only we could find Kat a boyfriend... \\n&lt;AGENT&gt;: Let me see what I can do. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                 conversation\n",
       "0  <USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \\n<USER>: Not the hacking and gagging and spitting part.  Please. \\n<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n\n",
       "1                                                                                                                                                                                                                                                                                             <USER>: You're asking me out.  That's so cute. What's your name again? \\n<AGENT>: Forget it. \\n\n",
       "2                                                                                          <USER>: No, no, it's my fault -- we didn't have a proper introduction --- \\n<AGENT>: Cameron. \\n<USER>: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \\n<AGENT>: Seems like she could get a date easy enough... \\n\n",
       "3                                                                                                                                                                                                                            <USER>: Why? \\n<AGENT>: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. \\n\n",
       "4                                                                                                                                                                                                                                                                                              <USER>: Gosh, if only we could find Kat a boyfriend... \\n<AGENT>: Let me see what I can do. \\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \n",
      "<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \n",
      "<USER>: Not the hacking and gagging and spitting part.  Please. \n",
      "<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Serialize dataset for faster loading\n",
    "if not dataset_generated:\n",
    "    with open(DATASET_FILENAME, \"wb\") as f:\n",
    "        print(\"Writing dataframe to file\")\n",
    "        pickle.dump(movie_conversations, f)\n",
    "else:\n",
    "    with open(DATASET_FILENAME, \"rb\") as f:\n",
    "        print(\"Loading dataframe from file\")\n",
    "        movie_conversations = pickle.load(f)\n",
    "\n",
    "display(movie_conversations.head())\n",
    "print(movie_conversations[\"conversation\"].head(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \n",
      "<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \n",
      "<USER>: Not the hacking and gagging and spitting part.  Please. \n",
      "<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \n",
      "\n",
      "Input:\n",
      " <USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \n",
      "<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \n",
      "<USER>: Not the hacking and gagging and spitting part.  Please.<AGENT>:\n",
      "Response:\n",
      " Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "<USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \n",
      "\n",
      " Well, I thought we'd start with pronunciation, if that's okay with you. \n",
      "<USER>: Not the hacking and gagging and spitting part.  Please. \n",
      "\n",
      " Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test splitting on last agent line\n",
    "test_string = movie_conversations[\"conversation\"].head(1).values[0]\n",
    "print(test_string)\n",
    "splits = test_string.split('<AGENT>:')\n",
    "response = splits[-1].strip()\n",
    "input = '<AGENT>:'.join(splits[:-1]).strip() + \"<AGENT>:\"\n",
    "print(\"Input:\\n\", input)\n",
    "print(\"Response:\\n\", response)\n",
    "for split in splits:\n",
    "    print(split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;USER&gt;: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n&lt;AGENT&gt;: Well, I thought we'd start with pronunciation, if that's okay with you. \\n&lt;USER&gt;: Not the hacking and gagging and spitting part.  Please. \\n&lt;AGENT&gt;: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n</td>\n",
       "      <td>&lt;USER&gt;: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n&lt;AGENT&gt;: Well, I thought we'd start with pronunciation, if that's okay with you. \\n&lt;USER&gt;: Not the hacking and gagging and spitting part.  Please.&lt;AGENT&gt;:</td>\n",
       "      <td>Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;USER&gt;: You're asking me out.  That's so cute. What's your name again? \\n&lt;AGENT&gt;: Forget it. \\n</td>\n",
       "      <td>&lt;USER&gt;: You're asking me out.  That's so cute. What's your name again?&lt;AGENT&gt;:</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;USER&gt;: No, no, it's my fault -- we didn't have a proper introduction --- \\n&lt;AGENT&gt;: Cameron. \\n&lt;USER&gt;: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \\n&lt;AGENT&gt;: Seems like she could get a date easy enough... \\n</td>\n",
       "      <td>&lt;USER&gt;: No, no, it's my fault -- we didn't have a proper introduction --- \\n&lt;AGENT&gt;: Cameron. \\n&lt;USER&gt;: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.&lt;AGENT&gt;:</td>\n",
       "      <td>Seems like she could get a date easy enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;USER&gt;: Why? \\n&lt;AGENT&gt;: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. \\n</td>\n",
       "      <td>&lt;USER&gt;: Why?&lt;AGENT&gt;:</td>\n",
       "      <td>Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;USER&gt;: Gosh, if only we could find Kat a boyfriend... \\n&lt;AGENT&gt;: Let me see what I can do. \\n</td>\n",
       "      <td>&lt;USER&gt;: Gosh, if only we could find Kat a boyfriend...&lt;AGENT&gt;:</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                 conversation  \\\n",
       "0  <USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \\n<USER>: Not the hacking and gagging and spitting part.  Please. \\n<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n   \n",
       "1                                                                                                                                                                                                                                                                                             <USER>: You're asking me out.  That's so cute. What's your name again? \\n<AGENT>: Forget it. \\n   \n",
       "2                                                                                          <USER>: No, no, it's my fault -- we didn't have a proper introduction --- \\n<AGENT>: Cameron. \\n<USER>: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \\n<AGENT>: Seems like she could get a date easy enough... \\n   \n",
       "3                                                                                                                                                                                                                            <USER>: Why? \\n<AGENT>: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. \\n   \n",
       "4                                                                                                                                                                                                                                                                                              <USER>: Gosh, if only we could find Kat a boyfriend... \\n<AGENT>: Let me see what I can do. \\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                      context  \\\n",
       "0  <USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \\n<USER>: Not the hacking and gagging and spitting part.  Please.<AGENT>:   \n",
       "1                                                                                                                                                                                                                              <USER>: You're asking me out.  That's so cute. What's your name again?<AGENT>:   \n",
       "2                                                               <USER>: No, no, it's my fault -- we didn't have a proper introduction --- \\n<AGENT>: Cameron. \\n<USER>: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.<AGENT>:   \n",
       "3                                                                                                                                                                                                                                                                                        <USER>: Why?<AGENT>:   \n",
       "4                                                                                                                                                                                                                                              <USER>: Gosh, if only we could find Kat a boyfriend...<AGENT>:   \n",
       "\n",
       "                                                                                                                                response  \n",
       "0                                                              Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?  \n",
       "1                                                                                                                             Forget it.  \n",
       "2                                                                                         Seems like she could get a date easy enough...  \n",
       "3  Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.  \n",
       "4                                                                                                              Let me see what I can do.  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test and evaluation sets, cut off the last agent response to create expected output to compare against for eval\n",
    "def create_response(text):\n",
    "    splits = text.split('<AGENT>:')\n",
    "    input = '<AGENT>:'.join(splits[:-1]).strip() + \"<AGENT>:\"\n",
    "    response = splits[-1].strip()\n",
    "\n",
    "    return pd.Series([input, response])\n",
    "\n",
    "movie_conversations[[\"context\", \"response\"]] = movie_conversations[\"conversation\"].apply(create_response)\n",
    "movie_conversations.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49863 entries, 30425 to 15795\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   conversation  49863 non-null  object\n",
      " 1   context       49863 non-null  object\n",
      " 2   response      49863 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16621 entries, 80426 to 70559\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   conversation  16621 non-null  object\n",
      " 1   context       16621 non-null  object\n",
      " 2   response      16621 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 519.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16621 entries, 39297 to 24595\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   conversation  16621 non-null  object\n",
      " 1   context       16621 non-null  object\n",
      " 2   response      16621 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 519.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into test, evaluation, and training sets\n",
    "train_data, temp_data = train_test_split(movie_conversations, train_size=0.6, random_state=42)\n",
    "print(train_data.info())\n",
    "\n",
    "eval_data, test_data = train_test_split(temp_data, train_size=0.5, random_state=42)\n",
    "print(eval_data.info())\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversation', 'context', 'response'],\n",
       "    num_rows: 49863\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframes to datasets\n",
    "train_dataset = Dataset.from_pandas(train_data, preserve_index=False)\n",
    "eval_dataset = Dataset.from_pandas(eval_data, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_data, preserve_index=False)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = pipeline('text-generation', model='gpt2-medium')\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"User: Hi, how are you? Agent: Ok, I guess it's time to show myself\"},\n",
       " {'generated_text': \"User: Hi, how are you? Agent: What's going on?! Player: Ok, I\"},\n",
       " {'generated_text': 'User: Hi, how are you? Agent: Hi! How would you like to play? What'},\n",
       " {'generated_text': \"User: Hi, how are you? Agent: I'm fine... Agent: What do you need\"},\n",
       " {'generated_text': \"User: Hi, how are you? Agent: Good, what happens is, I'm a person\"}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"User: Hi, how are you? Agent:\", max_length=20, num_return_sequences=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
