{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chardet\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from pandarallel import pandarallel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILENAME = \"movie_conversations.pkl\"\n",
    "MAX_TOKEN_LENGTH = 1024\n",
    "dataset_generated = False\n",
    "\n",
    "if os.path.exists(DATASET_FILENAME):\n",
    "    dataset_generated = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_generated:\n",
    "    # Detect encoding of the movie lines file\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    with open(cwd + \"/movie_lines/movie_lines.txt\", \"rb\") as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        movie_lines_encoding = result[\"encoding\"]\n",
    "\n",
    "    with open(cwd + \"/movie_lines/movie_conversations.txt\", \"rb\") as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        movie_conversations_encoding = result[\"encoding\"]\n",
    "\n",
    "    print(movie_lines_encoding)\n",
    "    print(movie_conversations_encoding)\n",
    "    # movie_lines_encoding = \"Windows-1252\"\n",
    "    # movie_conversations_encoding = \"ascii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!', 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!', 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.', 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?', \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"]\n",
      "304713\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    # Collect individual movie lines\n",
    "    with open(cwd + \"/movie_lines/movie_lines.txt\", \"r\", encoding=movie_lines_encoding) as f:\n",
    "        content = f.read()\n",
    "\n",
    "    lines = content.split(\"\\n\")\n",
    "\n",
    "    # Print first 5 lines and verify length is correct\n",
    "    print(lines[:5])\n",
    "\n",
    "    # Remove last element of lines because its an empty string\n",
    "    lines = lines[:-1]\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L1045': ('u0', 'They do not!'), 'L1044': ('u2', 'They do to!'), 'L985': ('u0', 'I hope so.'), 'L984': ('u2', 'She okay?'), 'L925': ('u0', \"Let's go.\"), 'L924': ('u2', 'Wow'), 'L872': ('u0', \"Okay -- you're gonna need to learn how to lie.\"), 'L871': ('u2', 'No'), 'L870': ('u0', 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'), 'L869': ('u0', 'Like my fear of wearing pastels?')}\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    # Initialize containers for values to put in dataframe\n",
    "    line_numbers_dict = {}\n",
    "\n",
    "    for line in lines:\n",
    "        # Split on whitespace\n",
    "        split = line.split(\" \")\n",
    "        line_number = split[0]\n",
    "        character_id = split[2]\n",
    "\n",
    "        # Extract the text after the last \"+\" character\n",
    "        l = re.split(r'\\+\\s+(?=[^+]*$)', line)[-1]\n",
    "        line_numbers_dict[line_number] = (character_id, l)\n",
    "\n",
    "\n",
    "    # Create dataframe from extracted values\n",
    "    print(dict(itertools.islice(line_numbers_dict.items(), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\"]\n",
      "83097\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    # Collect movie conversation lists\n",
    "    with open(cwd + \"/movie_lines/movie_conversations.txt\", \"r\", encoding=movie_conversations_encoding) as f:\n",
    "        content = f.read()\n",
    "\n",
    "    lines = content.split(\"\\n\")\n",
    "\n",
    "    # Print first 5 lines and verify length is correct\n",
    "    print(lines[:5])\n",
    "\n",
    "    # Remove last element of lines because its an empty string\n",
    "    lines = lines[:-1]\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker1_id</th>\n",
       "      <th>speaker2_id</th>\n",
       "      <th>conversation_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>[L194, L195, L196, L197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>[L198, L199]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>[L200, L201, L202, L203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>[L204, L205, L206]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>[L207, L208]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker1_id speaker2_id        conversation_lines\n",
       "0          u0          u2  [L194, L195, L196, L197]\n",
       "1          u0          u2              [L198, L199]\n",
       "2          u0          u2  [L200, L201, L202, L203]\n",
       "3          u0          u2        [L204, L205, L206]\n",
       "4          u0          u2              [L207, L208]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83097 entries, 0 to 83096\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   speaker1_id         83097 non-null  object\n",
      " 1   speaker2_id         83097 non-null  object\n",
      " 2   conversation_lines  83097 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    # Initialize containers for values to put in dataframe\n",
    "    speaker1_ids = []\n",
    "    speaker2_ids = []\n",
    "    conversation_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Split on whitespace\n",
    "        split = line.split(\" \")\n",
    "        speaker1_ids.append(split[0])\n",
    "        speaker2_ids.append(split[2])\n",
    "\n",
    "        # Extract the text after the last \"+\" character\n",
    "        l = re.split(r'\\+\\s+(?=[^+]*$)', line)[-1]\n",
    "        l = ast.literal_eval(l)\n",
    "        conversation_lines.append(l)\n",
    "\n",
    "\n",
    "    # Create dataframe from extracted values\n",
    "    movie_conversations = pd.DataFrame(list(zip(speaker1_ids, speaker2_ids, conversation_lines)), columns=[\"speaker1_id\", \"speaker2_id\", \"conversation_lines\"])\n",
    "    display(movie_conversations.head())\n",
    "    movie_conversations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for turning movie lines into multi-turn conversations for training\n",
    "def create_conversation_turns(row):\n",
    "    speaker1 = row[\"speaker1_id\"]\n",
    "    conversation_list = row[\"conversation_lines\"]\n",
    "    convo = \"\"\n",
    "    # For each line, add it to the conversation with a role label\n",
    "    for line_id in conversation_list:\n",
    "        movie_line = line_numbers_dict[line_id]\n",
    "        text = movie_line[1]\n",
    "\n",
    "        if movie_line[0] == speaker1:\n",
    "            convo += f\"<USER>: {text} \\n\"\n",
    "        else:\n",
    "            convo += f\"<AGENT>: {text} \\n\"\n",
    "        \n",
    "    return convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker1_id</th>\n",
       "      <th>speaker2_id</th>\n",
       "      <th>conversation_lines</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>[L194, L195, L196, L197]</td>\n",
       "      <td>&lt;USER&gt;: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n&lt;AGENT&gt;: Well, I thought we'd start with pronunciation, if that's okay with you. \\n&lt;USER&gt;: Not the hacking and gagging and spitting part.  Please. \\n&lt;AGENT&gt;: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>[L198, L199]</td>\n",
       "      <td>&lt;USER&gt;: You're asking me out.  That's so cute. What's your name again? \\n&lt;AGENT&gt;: Forget it. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker1_id speaker2_id        conversation_lines  \\\n",
       "0          u0          u2  [L194, L195, L196, L197]   \n",
       "1          u0          u2              [L198, L199]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 conversation  \n",
       "0  <USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \\n<USER>: Not the hacking and gagging and spitting part.  Please. \\n<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n  \n",
       "1                                                                                                                                                                                                                                                                                             <USER>: You're asking me out.  That's so cute. What's your name again? \\n<AGENT>: Forget it. \\n  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    # Try it on a sample for testing\n",
    "    sample = movie_conversations.copy().iloc[:2]\n",
    "    sample[\"conversation\"] = sample.apply(create_conversation_turns, axis=1)\n",
    "    display(sample)\n",
    "\n",
    "    # Call create_conversation_turns on every row of the dataframe\n",
    "    movie_conversations[\"conversation\"] = movie_conversations.apply(create_conversation_turns, axis=1)\n",
    "\n",
    "    # Drop speaker id columns because they aren't needed anymore\n",
    "    movie_conversations.drop(columns=[\"speaker1_id\", \"speaker2_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_lines</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[L194, L195, L196, L197]</td>\n",
       "      <td>&lt;USER&gt;: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n&lt;AGENT&gt;: Well, I thought we'd start with pronunciation, if that's okay with you. \\n&lt;USER&gt;: Not the hacking and gagging and spitting part.  Please. \\n&lt;AGENT&gt;: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[L198, L199]</td>\n",
       "      <td>&lt;USER&gt;: You're asking me out.  That's so cute. What's your name again? \\n&lt;AGENT&gt;: Forget it. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[L200, L201, L202, L203]</td>\n",
       "      <td>&lt;USER&gt;: No, no, it's my fault -- we didn't have a proper introduction --- \\n&lt;AGENT&gt;: Cameron. \\n&lt;USER&gt;: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \\n&lt;AGENT&gt;: Seems like she could get a date easy enough... \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[L204, L205, L206]</td>\n",
       "      <td>&lt;AGENT&gt;: Why? \\n&lt;USER&gt;: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. \\n&lt;AGENT&gt;: That's a shame. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[L207, L208]</td>\n",
       "      <td>&lt;USER&gt;: Gosh, if only we could find Kat a boyfriend... \\n&lt;AGENT&gt;: Let me see what I can do. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         conversation_lines  \\\n",
       "0  [L194, L195, L196, L197]   \n",
       "1              [L198, L199]   \n",
       "2  [L200, L201, L202, L203]   \n",
       "3        [L204, L205, L206]   \n",
       "4              [L207, L208]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 conversation  \n",
       "0  <USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \\n<USER>: Not the hacking and gagging and spitting part.  Please. \\n<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n  \n",
       "1                                                                                                                                                                                                                                                                                             <USER>: You're asking me out.  That's so cute. What's your name again? \\n<AGENT>: Forget it. \\n  \n",
       "2                                                                                          <USER>: No, no, it's my fault -- we didn't have a proper introduction --- \\n<AGENT>: Cameron. \\n<USER>: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \\n<AGENT>: Seems like she could get a date easy enough... \\n  \n",
       "3                                                                                                                                                                                                 <AGENT>: Why? \\n<USER>: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. \\n<AGENT>: That's a shame. \\n  \n",
       "4                                                                                                                                                                                                                                                                                              <USER>: Gosh, if only we could find Kat a boyfriend... \\n<AGENT>: Let me see what I can do. \\n  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \n",
      "<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \n",
      "<USER>: Not the hacking and gagging and spitting part.  Please. \n",
      "<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    display(movie_conversations.head())\n",
    "    print(movie_conversations[\"conversation\"].head(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    # Get the token count for each conversation so we can split the ones that are too long\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "    movie_conversations[\"token_count\"] = movie_conversations[\"conversation\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "    movie_conversations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([11348, 19670, 24318, 42477, 45571, 51994, 53303, 53320, 70355, 70455,\n",
      "       70670],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:    \n",
    "    # Get the conversation entries that are over the token limit\n",
    "    over_token_limit = movie_conversations[movie_conversations[\"token_count\"] > MAX_TOKEN_LENGTH].index\n",
    "    print(over_token_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83108 entries, 0 to 83107\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   conversation_lines  83108 non-null  object \n",
      " 1   conversation        83108 non-null  object \n",
      " 2   token_count         83086 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    # NOTE: Be careful not to run this more than once without reseting the dataframe\n",
    "    new_entries = []\n",
    "\n",
    "    # For each conversation that is too long, split it in half\n",
    "    for idx in over_token_limit:\n",
    "        lines_to_split = movie_conversations.iloc[idx][\"conversation_lines\"]\n",
    "        split_idx = (len(lines_to_split)//2)\n",
    "        first_half = lines_to_split[:split_idx]\n",
    "        second_half = lines_to_split[split_idx:]\n",
    "\n",
    "        first_convo = \"\"\n",
    "        second_convo = \"\"\n",
    "        # For each line, add it to the conversation\n",
    "        for i, line_id in enumerate(first_half):\n",
    "            movie_line = line_numbers_dict[line_id]\n",
    "            text = movie_line[1]\n",
    "\n",
    "            if i%2 == 0:\n",
    "                first_convo += f\"<USER>: {text} \\n\"\n",
    "            else:\n",
    "                first_convo += f\"<AGENT>: {text} \\n\"\n",
    "\n",
    "        new_entries.append({\"conversation_lines\": first_half, \"conversation\": first_convo})\n",
    "\n",
    "        for i, line_id in enumerate(second_half):\n",
    "            movie_line = line_numbers_dict[line_id]\n",
    "            text = movie_line[1]\n",
    "\n",
    "            if i%2 == 0:\n",
    "                second_convo += f\"<USER>: {text} \\n\"\n",
    "            else:\n",
    "                second_convo += f\"<AGENT>: {text} \\n\"\n",
    "\n",
    "        new_entries.append({\"conversation_lines\": second_half, \"conversation\": second_convo})\n",
    "\n",
    "    # Add the new entries from splitting and drop the originals\n",
    "    movie_conversations = pd.concat([movie_conversations, pd.DataFrame(new_entries)], axis=0, ignore_index=True)\n",
    "    movie_conversations.drop(index=over_token_limit, inplace=True)\n",
    "\n",
    "    movie_conversations.reset_index(inplace=True, drop=True)\n",
    "    movie_conversations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_lines</th>\n",
       "      <th>conversation</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [conversation_lines, conversation, token_count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    # Check that no conversations are over the token limit\n",
    "    display(movie_conversations[movie_conversations[\"token_count\"] > MAX_TOKEN_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataframe from file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_lines</th>\n",
       "      <th>conversation</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[L194, L195, L196, L197]</td>\n",
       "      <td>&lt;USER&gt;: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n&lt;AGENT&gt;: Well, I thought we'd start with pronunciation, if that's okay with you. \\n&lt;USER&gt;: Not the hacking and gagging and spitting part.  Please. \\n&lt;AGENT&gt;: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[L198, L199]</td>\n",
       "      <td>&lt;USER&gt;: You're asking me out.  That's so cute. What's your name again? \\n&lt;AGENT&gt;: Forget it. \\n</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[L200, L201, L202, L203]</td>\n",
       "      <td>&lt;USER&gt;: No, no, it's my fault -- we didn't have a proper introduction --- \\n&lt;AGENT&gt;: Cameron. \\n&lt;USER&gt;: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \\n&lt;AGENT&gt;: Seems like she could get a date easy enough... \\n</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[L204, L205, L206]</td>\n",
       "      <td>&lt;AGENT&gt;: Why? \\n&lt;USER&gt;: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. \\n&lt;AGENT&gt;: That's a shame. \\n</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[L207, L208]</td>\n",
       "      <td>&lt;USER&gt;: Gosh, if only we could find Kat a boyfriend... \\n&lt;AGENT&gt;: Let me see what I can do. \\n</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         conversation_lines  \\\n",
       "0  [L194, L195, L196, L197]   \n",
       "1              [L198, L199]   \n",
       "2  [L200, L201, L202, L203]   \n",
       "3        [L204, L205, L206]   \n",
       "4              [L207, L208]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 conversation  \\\n",
       "0  <USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \\n<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \\n<USER>: Not the hacking and gagging and spitting part.  Please. \\n<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \\n   \n",
       "1                                                                                                                                                                                                                                                                                             <USER>: You're asking me out.  That's so cute. What's your name again? \\n<AGENT>: Forget it. \\n   \n",
       "2                                                                                          <USER>: No, no, it's my fault -- we didn't have a proper introduction --- \\n<AGENT>: Cameron. \\n<USER>: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \\n<AGENT>: Seems like she could get a date easy enough... \\n   \n",
       "3                                                                                                                                                                                                 <AGENT>: Why? \\n<USER>: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. \\n<AGENT>: That's a shame. \\n   \n",
       "4                                                                                                                                                                                                                                                                                              <USER>: Gosh, if only we could find Kat a boyfriend... \\n<AGENT>: Let me see what I can do. \\n   \n",
       "\n",
       "   token_count  \n",
       "0        102.0  \n",
       "1         32.0  \n",
       "2         83.0  \n",
       "3         55.0  \n",
       "4         31.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<USER>: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. \n",
      "<AGENT>: Well, I thought we'd start with pronunciation, if that's okay with you. \n",
      "<USER>: Not the hacking and gagging and spitting part.  Please. \n",
      "<AGENT>: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not dataset_generated:\n",
    "    with open(DATASET_FILENAME, \"wb\") as f:\n",
    "        print(\"Writing dataframe to file\")\n",
    "        pickle.dump(movie_conversations, f)\n",
    "else:\n",
    "    with open(DATASET_FILENAME, \"rb\") as f:\n",
    "        print(\"Loading dataframe from file\")\n",
    "        movie_conversations = pickle.load(f)\n",
    "\n",
    "display(movie_conversations.head())\n",
    "print(movie_conversations[\"conversation\"].head(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-medium\"  # You can specify the desired model size\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.encode(conversation, return_tensors=\"pt\") for conversation in movie_conversations[\"conversation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 5e-5\n",
    "num_epochs = 1\n",
    "\n",
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts, tokenizer):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_texts[idx]\n",
    "\n",
    "dataset = ConversationDataset(tokenized_texts, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        inputs = batch.to(device)\n",
    "        labels = inputs.clone()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model, tokenizer, max_length=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=max_length)\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "prompt = \"User: Hello, how are you?\"\n",
    "response = generate_response(prompt, model, tokenizer)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
